{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"GVCF to VDS Pipeline Documentation","text":"<p>Welcome to the official documentation for the GVCF to VDS Pipeline. This tool facilitates the conversion of GVCF files into Hail VariantDataset (VDS) and provides common VDS operations.</p>"},{"location":"#table-of-contents","title":"Table of Contents","text":"<ul> <li>Installation</li> <li>Usage</li> <li>API Reference</li> <li>Contributing</li> <li>About</li> </ul>"},{"location":"about/","title":"About","text":"<p>This package is developed at the University of Tartu, Institute of Clinical Medicine under the project Oligogenic Inheritance in Genetic Diseases.</p>"},{"location":"about/#project-overview","title":"Project Overview","text":"<p>The GVCF to VDS Pipeline is designed to streamline the conversion of GVCF (Genomic VCF) files into Hail VariantDataset (VDS) format.</p>"},{"location":"about/#contact","title":"Contact","text":"<p>For more information or inquiries, please contact markus.marandi@ut.ee.</p>"},{"location":"api_reference/","title":"API Reference","text":""},{"location":"api_reference/#gvcf_to_vds_pipelineclicommand_setup","title":"<code>gvcf_to_vds_pipeline.cli.command_setup</code>","text":""},{"location":"api_reference/#setup_parser","title":"<code>setup_parser()</code>","text":"<p>Sets up the argument parser for the CLI tool.</p> <p>Returns:</p> <ul> <li><code>argparse.ArgumentParser</code>: Configured argument parser.</li> </ul>"},{"location":"api_reference/#command_handlersargs-conf","title":"<code>command_handlers(args, conf)</code>","text":"<p>Retrieves the appropriate handler function based on the command.</p> <p>Parameters:</p> <ul> <li><code>args</code>: Parsed command-line arguments.</li> <li><code>conf</code>: Configuration for Spark/Hail.</li> </ul> <p>Returns:</p> <ul> <li><code>dict</code>: Mapping of commands to their handler functions.</li> </ul>"},{"location":"api_reference/#setup_spark_configargs","title":"<code>setup_spark_config(args)</code>","text":"<p>Configures Spark settings based on provided arguments.</p> <p>Parameters:</p> <ul> <li><code>args</code>: Parsed command-line arguments.</li> </ul> <p>Returns:</p> <ul> <li><code>SparkConf</code>: Configured Spark configuration.</li> </ul>"},{"location":"api_reference/#gvcf_to_vds_pipelinedata_processinggvcfprocess","title":"<code>gvcf_to_vds_pipeline.data_processing.gvcf.process</code>","text":""},{"location":"api_reference/#build_or_combine_vdsgvcf_paths-output_path-existing_vdsnone","title":"<code>build_or_combine_vds(gvcf_paths, output_path, existing_vds=None)</code>","text":"<p>Combines multiple GVCF files into a single VDS.</p> <p>Parameters:</p> <ul> <li><code>gvcf_paths (list)</code>: List of paths to GVCF files.</li> <li><code>output_path (str)</code>: Path to save the combined VDS.</li> <li><code>existing_vds (str, optional)</code>: Path to an existing VDS to update.</li> </ul> <p>Returns:</p> <ul> <li><code>None</code></li> </ul>"},{"location":"api_reference/#gvcf_to_vds_pipelinedata_processinggvcfread","title":"<code>gvcf_to_vds_pipeline.data_processing.gvcf.read</code>","text":""},{"location":"api_reference/#read_gvcffile_path","title":"<code>read_gvcf(file_path)</code>","text":"<p>Reads a single GVCF file.</p> <p>Parameters:</p> <ul> <li><code>file_path (str)</code>: Path to the GVCF file.</li> </ul> <p>Returns:</p> <ul> <li><code>VariantDataset</code>: Parsed VariantDataset.</li> </ul>"},{"location":"api_reference/#gvcf_to_vds_pipelinedata_processingvdsoperations","title":"<code>gvcf_to_vds_pipeline.data_processing.vds.operations</code>","text":""},{"location":"api_reference/#filter_samplesvds-samples_to_keep","title":"<code>filter_samples(vds, samples_to_keep)</code>","text":"<p>Filters samples in the VDS.</p> <p>Parameters:</p> <ul> <li><code>vds (VariantDataset)</code>: The original VariantDataset.</li> <li><code>samples_to_keep (list)</code>: List of sample IDs to retain.</li> </ul> <p>Returns:</p> <ul> <li><code>VariantDataset</code>: Filtered VariantDataset.</li> </ul>"},{"location":"api_reference/#split_multivds","title":"<code>split_multi(vds)</code>","text":"<p>Splits multi-allelic variants in the VDS.</p> <p>Parameters:</p> <ul> <li><code>vds (VariantDataset)</code>: The original VariantDataset.</li> </ul> <p>Returns:</p> <ul> <li><code>VariantDataset</code>: VariantDataset with split multi-allelic variants.</li> </ul>"},{"location":"api_reference/#gvcf_to_vds_pipelineutilsconfig","title":"<code>gvcf_to_vds_pipeline.utils.config</code>","text":""},{"location":"api_reference/#load_configconfig_path","title":"<code>load_config(config_path)</code>","text":"<p>Loads configuration from a JSON file.</p> <p>Parameters:</p> <ul> <li><code>config_path (str)</code>: Path to the JSON configuration file.</li> </ul> <p>Returns:</p> <ul> <li><code>dict</code>: Configuration data.</li> </ul>"},{"location":"api_reference/#gvcf_to_vds_pipelineutilslogging","title":"<code>gvcf_to_vds_pipeline.utils.logging</code>","text":""},{"location":"api_reference/#setup_logginglog_level","title":"<code>setup_logging(log_level)</code>","text":"<p>Configures logging for the application.</p> <p>Parameters:</p> <ul> <li><code>log_level (str)</code>: Logging level (e.g., 'INFO', 'DEBUG').</li> </ul> <p>Returns:</p> <ul> <li><code>logging.Logger</code>: Configured logger.</li> </ul>"},{"location":"contributing/","title":"Contributing","text":"<p>Thank you for considering contributing to the GVCF to VDS Pipeline! Your contributions are highly appreciated.</p>"},{"location":"contributing/#how-to-contribute","title":"How to Contribute","text":"<p>1. Fork the Repository</p> <p>Click the \"Fork\" button at the top-right corner of the repository page to create your own fork.</p> <p>2. Clone Your Fork</p> <pre><code>git clone https://github.com/oligogeneticdiseases/gvcf-to-vds-pipeline.git\ncd gvcf-to-vds-pipeline\n</code></pre> <p>Make your changes and commit them to your fork.</p> <p>3. Create a Pull Request</p> <p>Once you have made your changes, push them to your fork and create a pull request. We will review your changes and merge them into the main repository.</p>"},{"location":"installation/","title":"Installation","text":""},{"location":"installation/#prerequisites","title":"Prerequisites","text":"<ul> <li>Python: Ensure you have Python 3.7 or higher installed.</li> <li>Hail: Required for VariantDataset operations.</li> <li>PySpark: Necessary for distributed data processing.</li> </ul>"},{"location":"installation/#install-via-pypi","title":"Install via PyPI","text":"<p>You can install the package using <code>pip</code>:</p>"},{"location":"installation/#steps","title":"Steps","text":"<ol> <li>Clone the repository:</li> </ol> <pre><code>git clone https://github.com/OligoGeneticDiseases/gvcf-to-vds-pipeline.git\ncd gvcf-to-vds-pipeline\n</code></pre> <ol> <li>(Optional) Create a virtual environment:</li> </ol> <pre><code>python3 -m venv venv\nsource venv/bin/activate\n</code></pre> <ol> <li>Install:</li> </ol> <pre><code>pip install .\n</code></pre> <ul> <li>This will install all necessary Python dependencies and a console script gvcf-to-vds.</li> </ul> <p>Verifying Installation * After install, run gvcf-to-vds --help. You should see a help message for the CLI. * Ensure that import hail works in a Python REPL. You may need to install or configure Spark/Hail if not already done.</p> <p>Troubleshooting * If you encounter Spark/Hail import errors, verify your environment variables and Java installations. * Mac OS or Windows users may need additional setup for PySpark. See Hail\u2019s platform notes.</p>"},{"location":"installation/#verify-installation","title":"Verify Installation","text":"<p>After installation, verify that the CLI tool is accessible:</p> <pre><code>gvcf-to-vds --help\n</code></pre>"},{"location":"usage/","title":"Usage","text":"<p>The GVCF to VDS Pipeline provides a command-line interface (CLI) to perform various operations. Below are the primary commands and their usage.</p>"},{"location":"usage/#available-commands","title":"Available Commands","text":"<ul> <li><code>readgvcfs</code>: Combine GVCF files into a VDS.</li> <li><code>filter_samples</code>: Filter samples in a VariantDataset.</li> <li><code>filter_intervals</code>: Filter intervals in a VDS.</li> <li><code>sample_qc</code>: Compute sample quality control metrics.</li> <li><code>split_multi</code>: Split multi-allelic variants in a VDS.</li> <li><code>to_dense_mt</code>: Convert a VariantDataset to a dense MatrixTable.</li> </ul>"},{"location":"usage/#command-syntax","title":"Command Syntax","text":"<pre><code>gvcf-to-vds &lt;command&gt; [options]\n</code></pre>"},{"location":"usage/#example-convert-gvcfs-to-vds","title":"Example: Convert GVCFs to VDS","text":"<p>The <code>readgvcfs</code> command reads GVCF files and converts them to VDS format.</p> <pre><code>gvcf-to-vds readgvcfs \\\n  -f /path/to/gvcf_files \\\n  -d /path/to/output_vds \\\n  --temp /path/to/temp_dir \\\n  --use_genome_intervals\n</code></pre>"},{"location":"usage/#detailed-command-usage","title":"Detailed Command Usage","text":"<p>For detailed information on each command, use the --help flag:</p> <pre><code>gvcf-to-vds &lt;command&gt; --help\n</code></pre> <p>Example</p> <pre><code>gvcf-to-vds readgvcfs --help\n</code></pre>"},{"location":"usage/#readgvcfs","title":"<code>readgvcfs</code>","text":"<p>Creates or updates a VDS by combining new GVCFs and/or an existing VDS.</p> <p>Basic Command:</p> <pre><code>gvcf-to-vds readgvcfs \\\n  -f /path/to/gvcfs_or_dir \\\n  -d /path/to/dest.vds \\\n  --temp /tmp/combine-temp \\\n  --use_genome_intervals \\\n  --save_plan /path/to/combine-plan.json\n</code></pre> <p>Key Options: *   -f, --file: GVCF file(s) or directory(ies). *   --vds_in: (Optional) Path to an existing VDS to combine into. *   -d, --dest: Output VDS path. *   --temp: Temporary directory for intermediate files. *   --use_genome_intervals or --use_exome_intervals: Hail default partitioning. *   --intervals: Custom intervals (e.g., chr1:1-1000000). *   --import_interval_size: Size of intervals for GVCF partitioning.</p>"},{"location":"usage/#filter_samples","title":"<code>filter_samples</code>","text":"<p>Includes or excludes specific samples from a VDS.</p> <pre><code>gvcf-to-vds filter_samples \\\n  -v /path/to/vds \\\n  -s sample_file.txt \\\n  -k \\\n  -o /path/to/output.vds\n</code></pre> <ul> <li>-v, --vds: Input VDS path.</li> <li>-s, --samples: Text file with one sample ID per line.</li> <li>-k, --keep: If provided, keeps listed samples; otherwise removes them.</li> <li>-o, --out: Output path (overwrites if omitted).</li> </ul> <p>filter_intervals</p> <p>Filters intervals in a VDS (either keeping or removing them).</p> <pre><code>gvcf-to-vds filter_intervals \\\n  -v /path/to/input.vds \\\n  -i chr1:1-1000000 chr2:500-1500 \\\n  --keep \\\n  -o /path/to/output.vds\n</code></pre> <ul> <li>-v, --vds: Input VDS path.</li> <li>-i, --intervals: One or more intervals (Hail locus format).</li> <li>--keep: Keep these intervals (default). If not set, remove them.</li> <li>-o, --out: Output VDS path.</li> </ul>"},{"location":"usage/#sample_qc","title":"<code>sample_qc</code>","text":"<p>Computes sample quality metrics on a VDS. Exports results to a file or prints to stdout.</p> <pre><code>gvcf-to-vds sample_qc \\\n  -v /path/to/input.vds \\\n  -o /path/to/output.tsv\n</code></pre> <ul> <li>-v, --vds: Input VDS path.</li> <li>-o, --out: Output table file (default prints to console).</li> </ul>"},{"location":"usage/#split_multi","title":"<code>split_multi</code>","text":"<p>Splits multi-allelic variants.</p> <pre><code>gvcf-to-vds split_multi \\\n  -v /path/to/input.vds \\\n  -o /path/to/split.vds \\\n  --filter_changed_loci\n</code></pre> <ul> <li>-v, --vds: Input VDS.</li> <li>-o, --out: Output (split) VDS.</li> <li>--filter_changed_loci: If set, filters variants whose locus changes after splitting.</li> </ul>"},{"location":"usage/#to_dense_mt","title":"<code>to_dense_mt</code>","text":"<p>Converts the sparse VDS representation into a dense Hail MatrixTable.</p> <pre><code>gvcf-to-vds to_dense_mt \\\n  -v /path/to/input.vds \\\n  -o /path/to/dense.mt\n</code></pre> <ul> <li>-v, --vds: Input VDS.</li> <li>-o, --out: Output dense MatrixTable path.</li> </ul>"}]}